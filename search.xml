<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>beats系列～3.beats部署</title>
      <link href="/2021/11/19/beats-bu-shu-3/"/>
      <url>/2021/11/19/beats-bu-shu-3/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​    Beats的部署方式和监控的日志/指标/心跳服务/安全漏洞有很多选择。可在kibana的‘Home’中‘Get started by adding your data’内添加被监控的数据来源。</p><p>​    被监控的服务可以是apache、rabbitmq、kafka、mysql….等等等等</p><p>​    以下将部署beats 容器以及监控docker的指标，并将数据通过logstash传输到elasticsearch，最终在kibana进行可视化展示。</p><h3 id="1-部署Beats"><a href="#1-部署Beats" class="headerlink" title="1. 部署Beats"></a>1. 部署Beats</h3><p><strong>1）官网安装配置</strong></p><p>​    在kibana的‘Home’中‘Get started by adding your data’ 选择需要加入被监控和采集的服务，比如使用metrics beats监控docker metrics。</p><p><img src="/medias/art_img/docker-metrics%E5%9B%BE1.png"></p><p>​    可根据官网的命令进行安装配置，</p><ul><li>下载metricbeat安装包</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -L -O https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-7.15.2-darwin-x86_64.tar.gz</span><br><span class="line">tar xzvf metricbeat-7.15.2-darwin-x86_64.tar.gz</span><br><span class="line">cd metricbeat-7.15.2-darwin-x86_64/</span><br></pre></td></tr></tbody></table></figure><ul><li>配置metricbeat.yml</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">output.elasticsearch:</span><br><span class="line">  hosts: ["elasticseatch:9200"]</span><br><span class="line">  username: "elastic"</span><br><span class="line">  password: "changeme"</span><br><span class="line">setup.kibana:</span><br><span class="line">  host: "kibana:5601"</span><br></pre></td></tr></tbody></table></figure><ul><li>启动docker.yml配置</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 启动docker配置</span><br><span class="line">./metricbeat modules enable docker</span><br><span class="line"></span><br><span class="line"># 编辑 vi /modules.d/docker.yml </span><br><span class="line">- module: docker</span><br><span class="line">  metricsets:</span><br><span class="line">    - container</span><br><span class="line">    - cpu</span><br><span class="line">    - diskio</span><br><span class="line">    - event</span><br><span class="line">    - healthcheck</span><br><span class="line">    - info</span><br><span class="line">    - memory</span><br><span class="line">    - network</span><br><span class="line">  period: 10s</span><br><span class="line">  hosts: ["unix:///var/run/docker.sock"]</span><br></pre></td></tr></tbody></table></figure><ul><li>启动 Metricbeat</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./metricbeat setup</span><br><span class="line">./metricbeat -e</span><br></pre></td></tr></tbody></table></figure><ul><li>kibana中检查是否接收到metricbeat docker的指标数据</li></ul><p><img src="/medias/art_img/metricbeat-docker%E6%A3%80%E6%9F%A5%E6%88%90%E5%8A%9F.png"></p><p><strong>2）docker安装</strong></p><p><strong>注意</strong>：使用docker进行安装metricbeat时，需要将network指定为docker-elk_elk，这样处于同一网络下的kibana、logstash、elasticsearch就可以相互之间通信。</p><ul><li>启动metricbeat容器</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name metricbeat --user=root --network=docker-elk_elk  -v /var/run/docker.sock:/var/run/docker.sock elastic/metricbeat:7.9.2</span><br></pre></td></tr></tbody></table></figure><ul><li>相关文件metricbeat.yml、docker.yml，以及启动命令都和上面的执行步骤一致</li></ul><p><strong>3） 安装失败处理</strong></p><p><strong>1&gt;</strong> 安装中出现截图中的错误：data path already locked by another beat. Please make sure that multiple beats are not sharing the same data path (path.data). </p><p><img src="/medias/art_img/docker-metrics-lock%E5%A4%B1%E8%B4%A5.png"></p><p>解决办法：删除data文件夹下的metricbeat.lock文件，然后重新执行./metricbeat -e 命令</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/share/metricbeat/data</span><br><span class="line">rm -rf metricbeat.lock</span><br></pre></td></tr></tbody></table></figure><h3 id="2-kibana监控docker效果"><a href="#2-kibana监控docker效果" class="headerlink" title="2. kibana监控docker效果"></a>2. kibana监控docker效果</h3><p><img src="/medias/art_img/docker-metrics%E5%9B%BE2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Beats </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、beat、elastic stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>beats系列～2.elastic stack部署</title>
      <link href="/2021/11/19/beats-elasticstack-bu-shu-2/"/>
      <url>/2021/11/19/beats-elasticstack-bu-shu-2/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​    本文中将使用docker-compose容器化的形式来安装部署elastic stack（ELK）服务，部署方式可参考地址：<a href="https://github.com/deviantony/docker-elk#initial-setup">https://github.com/deviantony/docker-elk#initial-setup</a></p><h3 id="1-部署"><a href="#1-部署" class="headerlink" title="1. 部署"></a>1. 部署</h3><p>基于<a href="https://github.com/deviantony/docker-elk#initial-setup">安装地址</a>提供的方式进行安装，安装过程如下图所示：</p><p><img src="/medias/art_img/docker-elk.gif" alt="docker-elk"></p><style>    img[alt="docker-elk"]{        width:80%;    }</style><p>通过以上方式将Elasticsearch、Logstash、Kibana安装成功。默认安装成功后，所有web端可访问站点的默认账号为elastic 密码为changeme</p><h3 id="2-network网络"><a href="#2-network网络" class="headerlink" title="2. network网络"></a>2. network网络</h3><p>使用docker-compose.yml进行部署，需要了解docker-compse中定义的内容：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">version: '3.2'</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  elasticsearch:</span><br><span class="line">    build:</span><br><span class="line">      context: elasticsearch/</span><br><span class="line">      args:</span><br><span class="line">        ELK_VERSION: $ELK_VERSION</span><br><span class="line">    volumes:</span><br><span class="line">      - type: bind</span><br><span class="line">        source: ./elasticsearch/config/elasticsearch.yml</span><br><span class="line">        target: /usr/share/elasticsearch/config/elasticsearch.yml</span><br><span class="line">        read_only: true</span><br><span class="line">      - type: volume</span><br><span class="line">        source: elasticsearch</span><br><span class="line">        target: /usr/share/elasticsearch/data</span><br><span class="line">    ports:</span><br><span class="line">      - "9200:9200"</span><br><span class="line">      - "9300:9300"</span><br><span class="line">    environment:</span><br><span class="line">      ES_JAVA_OPTS: "-Xmx256m -Xms256m"</span><br><span class="line">      ELASTIC_PASSWORD: changeme</span><br><span class="line">      # Use single node discovery in order to disable production mode and avoid bootstrap checks.</span><br><span class="line">      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html</span><br><span class="line">      discovery.type: single-node</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line"></span><br><span class="line">  logstash:</span><br><span class="line">    build:</span><br><span class="line">      context: logstash/</span><br><span class="line">      args:</span><br><span class="line">        ELK_VERSION: $ELK_VERSION</span><br><span class="line">    volumes:</span><br><span class="line">      - type: bind</span><br><span class="line">        source: ./logstash/config/logstash.yml</span><br><span class="line">        target: /usr/share/logstash/config/logstash.yml</span><br><span class="line">        read_only: true</span><br><span class="line">      - type: bind</span><br><span class="line">        source: ./logstash/pipeline</span><br><span class="line">        target: /usr/share/logstash/pipeline</span><br><span class="line">        read_only: true</span><br><span class="line">    ports:</span><br><span class="line">      - "5044:5044"</span><br><span class="line">      - "5000:5000/tcp"</span><br><span class="line">      - "5000:5000/udp"</span><br><span class="line">      - "9600:9600"</span><br><span class="line">    environment:</span><br><span class="line">      LS_JAVA_OPTS: "-Xmx256m -Xms256m"</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">    depends_on:</span><br><span class="line">      - elasticsearch</span><br><span class="line"></span><br><span class="line">  kibana:</span><br><span class="line">    build:</span><br><span class="line">      context: kibana/</span><br><span class="line">      args:</span><br><span class="line">        ELK_VERSION: $ELK_VERSION</span><br><span class="line">    volumes:</span><br><span class="line">      - type: bind</span><br><span class="line">        source: ./kibana/config/kibana.yml</span><br><span class="line">        target: /usr/share/kibana/config/kibana.yml</span><br><span class="line">        read_only: true</span><br><span class="line">    ports:</span><br><span class="line">      - "5601:5601"</span><br><span class="line">    networks:</span><br><span class="line">      - elk</span><br><span class="line">    depends_on:</span><br><span class="line">      - elasticsearch</span><br><span class="line"></span><br><span class="line">networks:</span><br><span class="line">  elk:</span><br><span class="line">    driver: bridge</span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">  elasticsearch:</span><br></pre></td></tr></tbody></table></figure><p>以上的配置需要了解一下几点：</p><ul><li>bridge网络：docker-compose.yml中定义了容器elasticsearch、logstash、kibana，并分别都定义了elk的network，表明这三个容器都是用bridge网络（<strong>表示连接到同一个网桥的docker容器可以相互通信</strong>）。</li><li>查看当前docker-compose up -d运行后的网络，可通过docker network ls进行查看，可以发现名称为docker-elk_elk的bridge网桥。</li><li>services下定义的elasticsearch、logstash、kibana会自动加到名为docker-elk_elk的bridge网桥中，并在网桥中分别叫elasticsearch、logstash、kibana。因此在logstash中如需访问kibana或者elasticsearch，可以直接访问<a href="http://kibana:5601/">http://kibana:5601</a> 或者<a href="http://elasticsearch:9200/">http://elasticsearch:9200</a></li><li>如果其他的容器也想访问elasticsearch、logstash、kibana这三个docker服务，即需要将待启动的容器加入到docker-elk_elk网络中即可。即 启动命令中添加network参数：docker run -itd –network docker-elk_elk …….</li></ul>]]></content>
      
      
      <categories>
          
          <category> Beats、elastic_stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、beat、elastic stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>beats系列～1.beats基础概念</title>
      <link href="/2021/11/19/beats-ji-chu-gai-nian-1/"/>
      <url>/2021/11/19/beats-ji-chu-gai-nian-1/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​    Beats作为Elastic Stack（Elasticsearch、Kibana、Logstash、Beats）中的一部分，能够安全可靠性的提供数据来源，最终将数据进行数据可视化、并提供数据实时搜索等功能。</p><p>​    Beats作为安装在客户端的工具，具备多种数据指标采集的工具。以下将每一个beat的功能。</p><h3 id="1-Beats概念"><a href="#1-Beats概念" class="headerlink" title="1. Beats概念"></a>1. Beats概念</h3><p>​    Beats是轻量级的的日志接收并推送到logstash 或 elasticsearch的程序集合。这些安装在客户端并收集日志信息 或 指标信息等工具，分别为filebeat、metricbeat、packetbeat、winglogbeat、heartbeat、auditbeat。</p><p>1）filebeat</p><p>​    最常用的日志收集和传送的工具</p><p>2）metricbeat</p><p>​    收集各种平台的指标数据。可参考：<a href="https://www.elastic.co/guide/en/beats/metricbeat/7.3/metricbeat-getting-started.html">https://www.elastic.co/guide/en/beats/metricbeat/7.3/metricbeat-getting-started.html</a></p><p>3）packetbeat</p><p>​    网络数据包分析器，用于捕获服务器之间的网络流量，应用于应用程序的性能监控</p><p>4）winglogbeat</p><p>​    专门为收集windows事件而设计的beat，用于分析安全事件、已安装的更新等</p><p>5）heartbeat</p><p>​    用于勘测服务器上的服务是否可访问。类似心跳服务</p><p>6）auditbeat</p><p>​    用于识别Linux的安全漏洞，配置更改，恶意行为等</p><h3 id="2-作用"><a href="#2-作用" class="headerlink" title="2. 作用"></a>2. 作用</h3><p>Beats在整个elastic stack中其起到的功能在如下的结构图中呈现，如下图所示：</p><p>​    <img src="/medias/art_img/elastic-stack%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="架构图"></p><style>    img[alt="架构图"]{        width:80%;    }</style><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      
      
      <categories>
          
          <category> Beats、elastic_stack </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、beat、elastic stack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elastalert系列～2.elastalert部署</title>
      <link href="/2021/11/16/elastalert-bu-shu-2/"/>
      <url>/2021/11/16/elastalert-bu-shu-2/</url>
      
        <content type="html"><![CDATA[<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>​    elastalert的部署可以分为三种方式，分别为：源码安装、pip安装、docker容器安装。elastalert的运行依赖是必须提前部署好elasticsearch服务，非需要安装kibana服务。</p><h3 id="1-ElastAlert安装"><a href="#1-ElastAlert安装" class="headerlink" title="1. ElastAlert安装"></a>1. ElastAlert安装</h3><h4 id="1-1-源码安装"><a href="#1-1-源码安装" class="headerlink" title="1.1 源码安装"></a>1.1 源码安装</h4><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装依赖</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> yum install gcc libffi-devel python-devel openssl-devel python-setuptools</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 拉取源码</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> git <span class="built_in">clone</span> https://github.com/Yelp/elastalert.git</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> elastalert</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装elastalert</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> python setup.py install</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载依赖包</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install -r requirements.txt</span></span><br></pre></td></tr></tbody></table></figure><p>修改配置</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据模板生成配置文件</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> cp config.yaml.example config.yaml</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改配置</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vim config.yaml</span></span><br></pre></td></tr></tbody></table></figure><h3 id="1-2-pip安装"><a href="#1-2-pip安装" class="headerlink" title="1.2 pip安装"></a>1.2 pip安装</h3><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装pip包</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> pip install elastalert</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 添加配置</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> vim config.yaml</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建索引</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> elastalert-create-index</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动指定config.yaml文件的elastalert</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> elastalert --verbose --config config.yaml</span></span><br></pre></td></tr></tbody></table></figure><h4 id="1-3-Docker容器安装"><a href="#1-3-Docker容器安装" class="headerlink" title="1.3 Docker容器安装"></a>1.3 Docker容器安装</h4><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下拉镜像</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> docker pull anjia0532/elastalert-docker</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 运行容器，依赖elasticsearch服务</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> docker run -itd --restart=always  --name elastalert --network host \</span></span><br><span class="line"><span class="bash">    -v /data/elastalert/rules:/opt/elastalert/rules \</span></span><br><span class="line"><span class="bash">    -e ELASTICSEARCH_HOST=<span class="string">"xx.xx.xx.xx"</span> \</span></span><br><span class="line"><span class="bash">    -e ELASTICSEARCH_PORT=9200 \</span></span><br><span class="line"><span class="bash">    -e CONTAINER_TIMEZONE=<span class="string">"Asia/Shanghai"</span>  \</span></span><br><span class="line"><span class="bash">    -e SET_CONTAINER_TIMEZONE=True \</span></span><br><span class="line"><span class="bash">    -e TZ=<span class="string">"Asia/Shanghai"</span> \</span></span><br><span class="line"><span class="bash">    -e SET_CONTAINER_TIMEZONE=True \</span></span><br><span class="line"><span class="bash">    -e ELASTALERT_BUFFER_TIME=10  \</span></span><br><span class="line"><span class="bash">    -e ELASTALERT_RUN_EVERY=1  \</span></span><br><span class="line"><span class="bash">    -e ELASTICSEARCH_USER=<span class="string">"elastic"</span> \</span></span><br><span class="line"><span class="bash">    -e ELASTICSEARCH_PASSWORD=<span class="string">'xxxxxxx'</span> \</span></span><br><span class="line"><span class="bash">    anjia0532/elastalert-docker</span></span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>​    共享本地/data/elastalert/rules规则文件到容器的/opt/elastalert/rules路径，rules中配置相关的yaml文件。配置文件内容如下。</p><h3 id="2-配置config-yaml"><a href="#2-配置config-yaml" class="headerlink" title="2. 配置config.yaml"></a>2. 配置config.yaml</h3><p>​        配置文件中主要修改几个必需的选项，比如：加载规则路径参数<code>rules_folder</code>、elasticsearch服务的ip地址<code>es_host</code>、elasticsearch服务开放的端口<code>es_port</code>等</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 用来加载rule的目录，默认是example_rules</span></span><br><span class="line">rules_folder: example_rules</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 用来设置定时向elasticsearch发送请求</span></span><br><span class="line">run_every:</span><br><span class="line">  minutes: 1</span><br><span class="line"><span class="meta">  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 用来设置请求里时间字段的范围</span></span><br><span class="line">buffer_time:</span><br><span class="line">  minutes: 15</span><br><span class="line"><span class="meta">  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> elasticsearch的host地址</span></span><br><span class="line">es_host: 192.168.232.191</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> elasticsearch 对应的端口号</span></span><br><span class="line">es_port: 9200</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可选的，es url前缀</span></span><br><span class="line"><span class="meta">#</span><span class="bash">es_url_prefix：elasticsearch</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可选的，查询es的方式，默认是GET</span></span><br><span class="line"><span class="meta">#</span><span class="bash">es_send_get_body_as：GET</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可选的，选择是否用SSL连接es，<span class="literal">true</span>或者<span class="literal">false</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">use_ssl: True</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">可选的，是否验证TLS证书，设置为<span class="literal">true</span>或者<span class="literal">false</span>，默认为- <span class="literal">true</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">verify_certs: True</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> es认证的username和password</span></span><br><span class="line"><span class="meta">#</span><span class="bash">es_username: someusername</span></span><br><span class="line"><span class="meta">#</span><span class="bash">es_password: somepassword</span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> elastalert产生的日志在elasticsearch中的创建的索引</span></span><br><span class="line">writeback_index: elastalert_status</span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 失败重试的时间限制</span></span><br><span class="line">alert_time_limit:</span><br><span class="line">  days: 2</span><br></pre></td></tr></tbody></table></figure><p>详情请参考文档：<a href="https://link.segmentfault.com/?enc=yiBEmaJAz/CTESCE7HbSdg==.VvLcKFnM7B26IK5hCTYkZtFOtnR1YGtVrEsHsp0rYsRxtLoY2H1+K3JYFQqmK8CxzXNHZls+Ezmo9lorcaTxJkNy29EaAnttkuU80xq3ij+kVbqoFza5NVS486+9tJdM">http://elastalert.readthedocs…</a></p><h3 id="3-创建ElastAlert索引"><a href="#3-创建ElastAlert索引" class="headerlink" title="3. 创建ElastAlert索引"></a>3. 创建ElastAlert索引</h3><p>通过搜索find命令，可以找到相关的elastalert命令：</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> find / -name elastalert*</span></span><br><span class="line">/xxxx/elastalert</span><br><span class="line">/xxxx/elastalert-create-index</span><br><span class="line">/xxxx/elastalert-rule-from-kibana</span><br><span class="line">/xxxx/elastalert-test-rule</span><br></pre></td></tr></tbody></table></figure><ul><li><code>elastalert-create-index</code>会创建一个索引，<code>ElastAlert</code> 会把执行记录存放到这个索引中，默认情况下，索引名叫 <code>elastalert_status</code>。其中有<code>4</code>个<code>_type</code>，都有自己的<code>@timestamp</code> 字段，所以同样也可以用<code>kibana</code>来查看这个索引的日志记录情况。</li><li><code>elastalert-rule-from-kibana</code>从<code>Kibana3</code>已保存的仪表盘中读取<code>Filtering</code> 设置，帮助生成<code>config.yaml</code>里的配置。不过注意，它只会读取 <code>filtering</code>，不包括<code>queries</code>。</li><li><code>elastalert-test-rule</code>测试自定义配置中的<code>rule</code>设置。</li></ul><p>执行<code>elastalert-create-index</code>命令在<code>ES</code>创建索引，这不是必须的步骤，但是强烈建议创建。因为对于审计和测试很有用，并且重启<code>ES</code>不影响计数和发送<code>alert</code>.</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> elastalert-create-index</span></span><br></pre></td></tr></tbody></table></figure><p>具体参见文档： <a href="https://link.segmentfault.com/?enc=kV0ukOes6sRgcc+ZrcECOA==.xNg1VpCyRrByFur7TjxhwNZYVshWYOQMv0T2yaMw0vvpE/mTxp8z2oQ9ERtqkykmANW5hAzuSDAYSuHZ7idwGg+2ka/QaJBIoNo6k3+P09THM9dRU1FatIjEgufmyAcl">setting-up-elasticsearch</a></p><h3 id="4-Rule配置"><a href="#4-Rule配置" class="headerlink" title="4. Rule配置"></a>4. Rule配置</h3><h4 id="4-1-Email告警"><a href="#4-1-Email告警" class="headerlink" title="4.1 Email告警"></a>4.1 Email告警</h4><p><code>rule</code>配置算是<code>ElastAlert</code>最核心的功能了，支持<code>11</code>种告警规则，就不一一介绍了，选用一个最为普遍使用的告警规则<code>frequency</code>，告警方式也选用最普遍的<code>email</code>。</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Alert when the rate of events exceeds a threshold</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (Optional)</span></span><br><span class="line"><span class="comment"># Elasticsearch host</span></span><br><span class="line"><span class="attr">es_host:</span> <span class="number">192.168</span><span class="string">.xxx.xxx</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (Optional)</span></span><br><span class="line"><span class="comment"># Elasticsearch port</span></span><br><span class="line"><span class="attr">es_port:</span> <span class="number">9200</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (OptionaL) Connect with SSL to Elasticsearch</span></span><br><span class="line"><span class="comment">#use_ssl: True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (Optional) basic-auth username and password for Elasticsearch</span></span><br><span class="line"><span class="comment">#es_username: someusername</span></span><br><span class="line"><span class="comment">#es_password: somepassword</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (Required)</span></span><br><span class="line"><span class="comment"># Rule name, must be unique</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">Example</span> <span class="string">frequency</span> <span class="string">rule</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (Required)</span></span><br><span class="line"><span class="comment"># Type of alert.</span></span><br><span class="line"><span class="comment"># the frequency rule type alerts when num_events events occur with timeframe time</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">frequency</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (Required)</span></span><br><span class="line"><span class="comment"># Index to search, wildcard supported</span></span><br><span class="line"><span class="attr">index:</span> <span class="string">metricbeat-*</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (Required, frequency specific)</span></span><br><span class="line"><span class="comment"># Alert when this many documents matching the query occur within a timeframe</span></span><br><span class="line"><span class="attr">num_events:</span> <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (Required, frequency specific)</span></span><br><span class="line"><span class="comment"># num_events must occur within this amount of time to trigger an alert</span></span><br><span class="line"><span class="attr">timeframe:</span></span><br><span class="line">  <span class="attr">hours:</span> <span class="number">4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (Required)</span></span><br><span class="line"><span class="comment"># A list of Elasticsearch filters used for find events</span></span><br><span class="line"><span class="comment"># These filters are joined with AND and nested in a filtered query</span></span><br><span class="line"><span class="comment"># For more info: http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/query-dsl.html</span></span><br><span class="line"><span class="attr">filter:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">query_string:</span></span><br><span class="line">    <span class="attr">query:</span> <span class="string">"system.process.cpu.total.pct: &gt;10%"</span>     <span class="string">//</span> <span class="string">field支持嵌套</span></span><br><span class="line"></span><br><span class="line"><span class="attr">smtp_host:</span> <span class="string">smtp.163.com</span></span><br><span class="line"><span class="attr">smtp_port:</span> <span class="number">25</span></span><br><span class="line"><span class="attr">smtp_auth_file:</span> <span class="string">/opt/elastalert/smtp_auth.yaml</span></span><br><span class="line"><span class="comment">#回复给那个邮箱</span></span><br><span class="line"><span class="attr">email_reply_to:</span> <span class="string">xxx@163.com</span></span><br><span class="line"><span class="comment">##从哪个邮箱发送</span></span><br><span class="line"><span class="attr">from_addr:</span> <span class="string">xxx@163.com</span></span><br><span class="line"><span class="comment"># (Required)</span></span><br><span class="line"><span class="comment"># The alert is use when a match is found</span></span><br><span class="line"><span class="attr">alert:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">"email"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (required, email specific)</span></span><br><span class="line"><span class="comment"># a list of email addresses to send alerts to</span></span><br><span class="line"><span class="attr">email:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">"yyy@qq.com"</span></span><br></pre></td></tr></tbody></table></figure><p>上述配置表示选择<code>metricbeat</code>作为告警索引，在<code>4</code>小时内将匹配过滤条件，当<code>CPU</code>使用百分比的值为<code>10%</code>超过<code>5</code>次后，即满足告警条件，然后发送邮件。</p><h4 id="4-2-邮件配置"><a href="#4-2-邮件配置" class="headerlink" title="4.2 邮件配置"></a>4.2 邮件配置</h4><p>​    上述配置中已经展示了一部分邮件配置，主要有<code>smtp host</code>、<code>smtp port</code>、<code>from addr</code>和<code>to_addr</code>等。这里笔者选择一个网易<code>163</code>的邮箱作为发送邮箱，一个<code>QQ</code>邮箱作为接收邮件进行测试，所以<code>smpt host</code>应该为<code>smtp.163.com</code>。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">smtp_host: smtp.163.com</span><br><span class="line">smtp_port: 25</span><br><span class="line">smtp_auth_file: /opt/elastalert/smtp_auth.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash">回复给那个邮箱</span></span><br><span class="line">email_reply_to: xxx@163.com</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#从哪个邮箱发送</span></span></span><br><span class="line">from_addr: xxx@163.com</span><br><span class="line"><span class="meta">#</span><span class="bash"> (Required)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The alert is use when a match is found</span></span><br><span class="line">alert:</span><br><span class="line">- "email"</span><br><span class="line"><span class="meta">#</span><span class="bash"> (required, email specific)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> a list of email addresses to send alerts to</span></span><br><span class="line">email:</span><br><span class="line">- "yyy@qq.com"</span><br></pre></td></tr></tbody></table></figure><p>还有一个<code>smtp_auth.yaml</code>文件，这个里面记录了发送邮箱的账号和密码，<code>163</code>邮箱有授权码机制，所以密码处应该填写授权码（没有的话则需要开启）。</p><figure class="highlight shell"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">发送邮件的邮箱</span></span><br><span class="line">user: xxx@163.com</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#不是邮箱密码，是设置的POP3密码</span></span></span><br><span class="line">password: xxx</span><br></pre></td></tr></tbody></table></figure><h4 id="4-3-避免重复告警"><a href="#4-3-避免重复告警" class="headerlink" title="4.3 避免重复告警"></a>4.3 避免重复告警</h4><p>避免一定时间段中重复告警，可以配置<code>realert</code>和<code>exponential_realert</code>这两个选项：</p><figure class="highlight clean"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># <span class="number">5</span>分钟内相同的报警不会重复发送</span><br><span class="line">realert:</span><br><span class="line">  minutes: <span class="number">5</span></span><br><span class="line"></span><br><span class="line"># 指数级扩大 realert 时间，中间如果有报警，</span><br><span class="line"># 则按照<span class="number">5</span>-&gt;<span class="number">10</span>-&gt;<span class="number">20</span>-&gt;<span class="number">40</span>-&gt;<span class="number">60</span>不断增大报警时间到制定的最大时间，</span><br><span class="line"># 如果之后报警减少，则会慢慢恢复原始realert时间</span><br><span class="line">exponential_realert:</span><br><span class="line">  hours: <span class="number">1</span></span><br></pre></td></tr></tbody></table></figure><h4 id="4-4-聚合相同告警"><a href="#4-4-聚合相同告警" class="headerlink" title="4.4 聚合相同告警"></a>4.4 聚合相同告警</h4><figure class="highlight delphi"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 根据报警的内，将相同的报警 根据<span class="keyword">name</span>来聚合</span><br><span class="line">aggregation_key: <span class="keyword">name</span></span><br><span class="line"></span><br><span class="line"># 聚合报警的内容，只展示 <span class="keyword">name</span> 与 <span class="keyword">message</span></span><br><span class="line">summary_table_fields:</span><br><span class="line">  - <span class="keyword">name</span></span><br><span class="line">  - <span class="keyword">message</span></span><br></pre></td></tr></tbody></table></figure><h4 id="4-5-告警内容格式化"><a href="#4-5-告警内容格式化" class="headerlink" title="4.5 告警内容格式化"></a>4.5 告警内容格式化</h4><p>​    可以自定义告警内容，内部是使用<code>Python</code>的<code>format</code>来实现的。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">alert_subject: "Error {} @{}"</span><br><span class="line">alert_subject_args:</span><br><span class="line">  - name</span><br><span class="line">  - "@timestamp"</span><br><span class="line"></span><br><span class="line">alert_text_type: alert_text_only</span><br><span class="line">alert_text: |</span><br><span class="line">  ### Error frequency exceeds</span><br><span class="line">  &gt; Name: {}</span><br><span class="line">  &gt; Message: {}</span><br><span class="line">  &gt; Host: {} ({})</span><br><span class="line">alert_text_args:</span><br><span class="line">  - name</span><br><span class="line">  - message</span><br><span class="line">  - hostname</span><br><span class="line">  - host</span><br></pre></td></tr></tbody></table></figure><p>当然还有更多高级配置，详情请参考文档。</p><h4 id="4-6-调试测试Rule"><a href="#4-6-调试测试Rule" class="headerlink" title="4.6 调试测试Rule"></a>4.6 调试测试Rule</h4><p>【手动测试】可以在运行<code>rule</code>之前先通过<code>elastalert-test-rule</code>命令来测试一下</p><figure class="highlight arcade"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ elastalert-test-rule ~<span class="regexp">/elastalert/</span>example_rules/example_frequency.yaml</span><br></pre></td></tr></tbody></table></figure><p>详情参考文档：<a href="https://link.segmentfault.com/?enc=kTILo9tLVnVXyrrDUyxdgA==.oJ4zXrQJyaqU/YrtJuMe2rhYU/hfm1Ul/276pOxwJkwLGSHOREzZro0TOXtu50R2/ITDn4qK5HE690Gklcee2oeIDDkl84JAmiyvFrb3VLvv93mxlazVKtJArbB4YIiL">http://elastalert.readthedocs…</a></p><h4 id="4-7-正式运行Rule"><a href="#4-7-正式运行Rule" class="headerlink" title="4.7 正式运行Rule"></a>4.7 正式运行Rule</h4><p>【手动运行】启动<code>elastalert</code>服务，监听<code>es</code>，这里加了<code>--rule example_frequency.yaml</code>表示只运行<code>example_frequency.yaml</code>这一个<code>rule</code>文件，如果不加该选项则会运行<code>rules_folder</code>下所有<code>rule</code>文件，上面配置中的<code>rules_folder</code>为默认的<code>example_rules</code>。</p><figure class="highlight stylus"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python -m elastalert<span class="selector-class">.elastalert</span> --verbose --rule example_frequency.yaml</span><br></pre></td></tr></tbody></table></figure><p>为了让服务后台运行并且可以达到守护进程的效果，在生产环境中推荐使用<code>supervisor</code>进行管理</p><h3 id="5-elastalert-kibana-plugin插件"><a href="#5-elastalert-kibana-plugin插件" class="headerlink" title="5. elastalert-kibana-plugin插件"></a>5. elastalert-kibana-plugin插件</h3><p><code>    elastalert-kibana-plugin</code>是围绕<code>elastalert</code>做的一个<code>kibana</code>展示插件，可以在<code>kibana</code>上创建、编辑和删除告警。</p><p>关于elastalert-kibana-plugin插件的使用与配置很复杂，暂不写</p><h3 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h3><p>​    官方网站：<a href="https://github.com/Yelp/elastalert">https://github.com/Yelp/elastalert</a>  也提供了容器化运行elastalert的配置，但是官网提供的命令依旧是很模糊，命令中的目录都要对应修改，具体参考上面配置文件即可，最重要的还是要明白整体架构，这样才能用好elastalert。</p><figure class="highlight awk"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run -d -p <span class="number">3030</span>:<span class="number">3030</span> \</span><br><span class="line">    -v `pwd`<span class="regexp">/config/</span>elastalert.yaml:<span class="regexp">/opt/</span>elastalert/config.yaml \</span><br><span class="line">    -v `pwd`<span class="regexp">/config/</span>config.json:<span class="regexp">/opt/</span>elastalert-server<span class="regexp">/config/</span>config.json \</span><br><span class="line">    -v `pwd`<span class="regexp">/rules:/</span>opt<span class="regexp">/elastalert/</span>rules \</span><br><span class="line">    -v `pwd`<span class="regexp">/rule_templates:/</span>opt<span class="regexp">/elastalert/</span>rule_templates \</span><br><span class="line">    --net=<span class="string">"host"</span> \</span><br><span class="line">    --name elastalert bitsensor/elastalert:latest</span><br></pre></td></tr></tbody></table></figure>]]></content>
      
      
      <categories>
          
          <category> Elastalert </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、elastalert </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elastalert系列～1.elastalert基础概念</title>
      <link href="/2021/11/16/elastalert-ji-chu-gai-nian-1/"/>
      <url>/2021/11/16/elastalert-ji-chu-gai-nian-1/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​    在企业中一般日志都采用ELK（elasticsearch、logstash、kibana）进行采集，通过kibana提供的可视化界面进行查看，但是日志告警的的方案很少。因此日志告警将采用elastAlert进行扩展。</p><p>​    <strong>从 Elastalert 0.2.0 开始，你必须使用 Python 3.6。将不再支持 Python 2</strong></p><p>elastalert 开源地址：<a href="https://github.com/Yelp/elastalert">https://github.com/Yelp/elastalert</a></p><h3 id="1-elastalert简介"><a href="#1-elastalert简介" class="headerlink" title="1. elastalert简介"></a>1. elastalert简介</h3><p>​    日志告警 即 对日志进行监控，如果发现日志中出现特定的信息，就触发报警功能。这是一种独立的，没有侵入性的技术。</p><p>​    日志告警的优点在于，告警规则可以独立于应用程序，应用程序只需要使用log4j这样的日志框架打印日志，日志告警引擎负责收集分析这些日志，当匹配规则时，发送报警，架构的耦合性是非常低的。</p><p>以下阐述一个简单的elastalert产生告警的流程：</p><p>1）本地产生日志的程序</p><p>2）本地日志收集的文件</p><p>3）filebeat采集日志文件，并推送到elasticsearch中</p><p>4）elasticsearch提供存储和查询的接口API服务</p><p>5）elastalert通过API查询日志，并匹配告警规则，进行告警</p><h3 id="2-工作原理"><a href="#2-工作原理" class="headerlink" title="2. 工作原理"></a>2. 工作原理</h3><p>elastalert的工作方式，如下三点：</p><p>1）周期性访问elasticsearch，即 配置 run_every参数</p><p>2）数据传入elastalert的规则引擎</p><p>3）数据与规则引擎中的规则（加载的rule规则文件）进行匹配</p><h3 id="3-规则类型"><a href="#3-规则类型" class="headerlink" title="3. 规则类型"></a>3. 规则类型</h3><p>ElastAlert包含几种具有常见监视范例的规则类型：</p><ul><li>“匹配Y时间至少有X个事件发生”（<code>frequency type</code>）</li><li>“当事件发生率增加或减少时进行匹配”（<code>spike type</code>）</li><li>“在Y时间内少于X个事件时进行匹配”（<code>flatline type</code>）</li><li>“当某个字段与黑名单/白名单匹配时匹配”（<code>blacklist</code>和<code>whitelist type</code>）</li><li>“匹配与给定过滤器匹配的任何事件”（<code>any type</code>）</li><li>“当某个字段在一段时间内具有两个不同的值时进行匹配”（<code>change type</code>）</li></ul><h3 id="4-案例规则"><a href="#4-案例规则" class="headerlink" title="4. 案例规则"></a>4. 案例规则</h3><p>​    <strong>告警规则</strong>: 如果在4小时内有50多个带有some_field == some_value的文档，请发送电子邮件至<a href="mailto:elastalert@example.com">elastalert@example.com</a></p><p>【案例】使用frequency规则，匹配一定时间内至少有一定数量的事件发生时，以下规则匹配。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># ES的ip和端口号</span><br><span class="line">es_host: elasticsearch.example.com</span><br><span class="line">es_port: 9200</span><br><span class="line"> </span><br><span class="line"># 规则名称</span><br><span class="line">name: Example rule</span><br><span class="line">type: frequency</span><br><span class="line"> </span><br><span class="line"># ES索引</span><br><span class="line">index: logstash-*</span><br><span class="line">num_events: 50</span><br><span class="line">timeframe:</span><br><span class="line">    hours: 4</span><br><span class="line">filter:</span><br><span class="line">- term:</span><br><span class="line">    some_field: "some_value"</span><br><span class="line">alert:</span><br><span class="line">- "email"</span><br><span class="line">email:</span><br><span class="line">- "elastalert@example.com"</span><br></pre></td></tr></tbody></table></figure><p>字段说明：</p><ul><li><strong>es_host</strong>和<strong>es_port</strong>应指向我们要查询的Elasticsearch集群。</li><li><strong>name</strong>：定义规则的唯一名称，否则ElastAlert将不会启动。</li><li><strong>type</strong>：每个规则具有不同的类型，可能采用不同的参数。频率类型表示“在时间范围内发生超过num_event个事件时发出警报。”</li><li><strong>index</strong>：要查询的索引的名称。如果您使用的是Logstash，则默认情况下索引将匹配“ <strong>logstash- *</strong> ”。</li><li><strong>num_events</strong>：此参数特定于频率类型，并且是触发警报时的阈值。</li><li><strong>timeframe</strong> 是必须发生num_events的时间段。</li><li><strong>filter</strong>是用于过滤结果的Elasticsearch过滤器列表。在这里，我们为带有some_field匹配some_value的文档提供了一个单项过滤器。如果不需要过滤器，则应将其指定为空列表：filter：[]</li><li><strong>alert</strong>是在每次比赛中运行的警报的列表。电子邮件警报要求使用SMTP服务器发送邮件。默认情况下，它将尝试使用localhost。可以使用<strong>smtp_host</strong>选项进行更改。</li><li><strong>email</strong> 是警报将发送到的地址列表。</li><li><strong>Type: change</strong> -此规则将监视特定字段，并在该字段更改时匹配。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Elastalert </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、elastalert </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>minemeld系列～3.minemeld miner创建与应用</title>
      <link href="/2021/11/11/minemeld-miner-chuang-jian-yu-ying-yong-3/"/>
      <url>/2021/11/11/minemeld-miner-chuang-jian-yu-ying-yong-3/</url>
      
        <content type="html"><![CDATA[<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>​    通过上一篇文章已经能用docker进行容器化部署MineMeld服务了，本章中将安装应用youtube-miner和github-miner，以及自定义miner。</p><p>1）youtube-miner 地址： <a href="https://github.com/PaloAltoNetworks/youtube-miner">https://github.com/PaloAltoNetworks/youtube-miner</a></p><p>2）github-miner 地址：<a href="https://github.com/lampwins/github-miner">https://github.com/lampwins/github-miner</a></p><h3 id="1-安装miner"><a href="#1-安装miner" class="headerlink" title="1. 安装miner"></a>1. 安装miner</h3><p>​    miner的安装方式分为2种，分别为源码安装、以及 wheel包安装</p><h5 id="1）以下展示源码安装，即youtube-miner的安装方式，即"><a href="#1）以下展示源码安装，即youtube-miner的安装方式，即" class="headerlink" title="1）以下展示源码安装，即youtube-miner的安装方式，即"></a>1）以下展示源码安装，即youtube-miner的安装方式，即<img src="https://paloaltonetworks.github.io/youtube-miner/mm-git-extension.gif?_=2" alt="Installation" title="Installation"></h5><h5 id="2）以下采用wheel包安装"><a href="#2）以下采用wheel包安装" class="headerlink" title="2）以下采用wheel包安装"></a>2）以下采用wheel包安装</h5><p>先将源码pull拉取下来，然后通过打包命令，生成对应的wheel包</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install wheel</span><br><span class="line"></span><br><span class="line">python setup.py sdist bidet_wheel</span><br></pre></td></tr></tbody></table></figure><p>然后再到MineMeld的 ‘SYSTEM’ –&gt; ‘EXTENSIONS’  界面中选择上传安装wheel文件。</p><p>以上安装方式都可行</p><h3 id="2-自定义MineMeld配置"><a href="#2-自定义MineMeld配置" class="headerlink" title="2. 自定义MineMeld配置"></a>2. 自定义MineMeld配置</h3><h4 id="2-1-默认Node配置"><a href="#2-1-默认Node配置" class="headerlink" title="2.1 默认Node配置"></a>2.1 默认Node配置</h4><p>​    MineMeld的配置是committed-config.yml文件，在docker容器中的位置在/opt/minemeld/local/config/committed-config.yml。默认该文件配置了以下内容：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">nodes:</span><br><span class="line">  spamhaus_EDROP:</span><br><span class="line">    output: true</span><br><span class="line">    prototype: spamhaus.EDROP</span><br><span class="line">  dshield_blocklist:</span><br><span class="line">    output: true</span><br><span class="line">    prototype: dshield.block</span><br><span class="line">  inboundaggregator:</span><br><span class="line">    inputs:</span><br><span class="line">      - spamhaus_DROP</span><br><span class="line">      - spamhaus_EDROP</span><br><span class="line">      - dshield_blocklist</span><br><span class="line">      - wlWhiteListIPv4</span><br><span class="line">    output: true</span><br><span class="line">    prototype: stdlib.aggregatorIPv4Inbound</span><br><span class="line">  inboundfeedhc:</span><br><span class="line">    inputs:</span><br><span class="line">      - inboundaggregator</span><br><span class="line">    output: false</span><br><span class="line">    prototype: stdlib.feedHCGreen</span><br><span class="line">  spamhaus_DROP:</span><br><span class="line">    output: true</span><br><span class="line">    prototype: spamhaus.DROP</span><br><span class="line">  wlWhiteListIPv4:</span><br><span class="line">    inputs: []</span><br><span class="line">    output: true</span><br><span class="line">    prototype: stdlib.listIPv4Generic</span><br><span class="line">  inboundfeedlc:</span><br><span class="line">    inputs:</span><br><span class="line">      - inboundaggregator</span><br><span class="line">    output: false</span><br><span class="line">    prototype: stdlib.feedLCGreen</span><br><span class="line">  inboundfeedmc:</span><br><span class="line">    inputs:</span><br><span class="line">      - inboundaggregator</span><br><span class="line">    output: false</span><br><span class="line">    prototype: stdlib.feedMCGreen</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>MineMeld默认了4个miner、1个processor、3个outputs，具体每一个Node节点的功能可参考 ‘minemeld系列～1.minemeld基础概念’中的讲解。</p><p>以上的默认配置构建了如下图中所示的mimer、processor、outputs:</p><p><img src="/medias/art_img/minemeld%E7%BB%93%E6%9E%84%E5%9B%BE2.png" alt="结构图"></p><style>    img[alt="结构图"]{        width: 60%;    }</style><h4 id="2-2-自定义处理流程"><a href="#2-2-自定义处理流程" class="headerlink" title="2.2 自定义处理流程"></a>2.2 自定义处理流程</h4><p>​    自定义处理流程需要修改三个内容：</p><ul><li>committed-config.yml：容器中位置/opt/minemeld/local/config/committed-config.yml</li><li>新增prototype文件，如 deal_ip.yml文件：新增文件放于容器中位置/opt/minemeld/prototypes/0.9.70 或 /opt/minemeld/prototypes/current 中，具体位置有待测试</li><li>新增miner、processor、outputs组件的处理逻辑：新增的可执行文件（如deal_ip.py文件）存放在/opt/minemeld/engine/0.9.70.post5/lib/python2.7/site-packages/minemeld/ft 路径下</li></ul><h4 id="2-3-案例"><a href="#2-3-案例" class="headerlink" title="2.3 案例"></a>2.3 案例</h4><p>以下定义的配置，是直接在容器中修改，<strong>未测试结果</strong>。</p><p>配置修改如下：</p><p>1）修改committed-config.yml中的内容，如下所示：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">nodes:</span><br><span class="line"></span><br><span class="line">  douban_input:</span><br><span class="line">    inputs: []</span><br><span class="line">    output: true</span><br><span class="line">    prototype: douban_pro.DoubanInClass</span><br><span class="line"></span><br><span class="line">  douban_processor:</span><br><span class="line">    inputs:</span><br><span class="line">      - douban_input</span><br><span class="line">    node_type: processor</span><br><span class="line">    prototype: douban_pro.DouBanProcessorClass</span><br><span class="line"></span><br><span class="line">  douban_output:</span><br><span class="line">    inputs:</span><br><span class="line">      - douban_processor</span><br><span class="line">    outputs: false</span><br><span class="line">    prototype: douban_pro.DouBanOutClass</span><br></pre></td></tr></tbody></table></figure><p>​    committed-config.yml中定义的输入douban_input、处理器douban_processor、输出douban_output。并定义在prototype文件中deal_ip.yml内的处理逻辑</p><p>2）新增deal_ip.yml中的内容如下：</p><p>​    deal_ip.py文件主要实现类方法DoubanInClass、DoubanProcessorClass、DoubanOutClass。即真正的逻辑处理这些类方法中实现</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">url: https://www.douban.com/</span><br><span class="line">description: &gt;</span><br><span class="line">  test minemeld douban-miner</span><br><span class="line"></span><br><span class="line">prototypes:</span><br><span class="line">    DouBanIn:</span><br><span class="line">        author: whf</span><br><span class="line">        development_status: STABLE</span><br><span class="line">        node_type: miner</span><br><span class="line">        description: douban movie logs</span><br><span class="line">        config:</span><br><span class="line">            key: douban test</span><br><span class="line">            age_out:</span><br><span class="line">                default: 30</span><br><span class="line">                sudden_death: true</span><br><span class="line">        interval: 50000</span><br><span class="line">        class: minemeld.ft.deal_ip.DoubanInClass</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    DouBanProcessor:</span><br><span class="line">        author: whf</span><br><span class="line">        development_status: STABLE</span><br><span class="line">        node_type: processor</span><br><span class="line">        tags: []</span><br><span class="line">        description: &gt;</span><br><span class="line">            douban logs processor</span><br><span class="line">        class: minemeld.ft.deal_ip.DoubanProcessorClass</span><br><span class="line">        config:</span><br><span class="line">            key: douban processor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    DouBanOut:</span><br><span class="line">        author: whf</span><br><span class="line">        development_status: STABLE</span><br><span class="line">        node_type: output</span><br><span class="line">        description: &gt;</span><br><span class="line">          douban logs putputs</span><br><span class="line">        class: minemeld.ft.deal_ip.DoubanOutClass</span><br><span class="line">        config:</span><br><span class="line">            key: douban outputs</span><br><span class="line"></span><br></pre></td></tr></tbody></table></figure><p>3）新增deal_ip.py的内容，如下:</p><p>以下实现的类方法DoubanInClass、DoubanProcessorClass、DoubanOutClass 仅供参考。主要了解四个方法：</p><ul><li>__init__</li><li>configure: 加载配置文件，从deal_ip.yml的config中获取配置参数</li><li>_process_item: 返回组装的数据</li><li>_build_iterator: 返回迭代列表对象</li></ul><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">from . import basepoller</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DoubanInClass(basepoller.BasePollerFT):</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, chassis, config):</span><br><span class="line">        super(DoubanInClass, self).__init__(name, chassis, config)</span><br><span class="line"></span><br><span class="line">    def configure(self):</span><br><span class="line">        super(DoubanInClass, self).configure()</span><br><span class="line">        self.key = self.config.get('key', None)</span><br><span class="line">        self.interval = self.config.get('interval', 80000)</span><br><span class="line"></span><br><span class="line">    def _process_item(self, item):</span><br><span class="line">        return [[item[0], item[1]]]</span><br><span class="line"></span><br><span class="line">    def _build_iterator(self, now):</span><br><span class="line">        yield 'input', 'test'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DoubanProcessorClass(basepoller.BasePollerFT):</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, chassis, config):</span><br><span class="line">        super(DoubanInClass, self).__init__(name, chassis, config)</span><br><span class="line"></span><br><span class="line">    def configure(self):</span><br><span class="line">        super(DoubanInClass, self).configure()</span><br><span class="line">        self.key = self.config.get('key', None)</span><br><span class="line">        self.interval = self.config.get('interval', 80000)</span><br><span class="line"></span><br><span class="line">    def _process_item(self, item):</span><br><span class="line">        return [[item[0], item[1]]]</span><br><span class="line"></span><br><span class="line">    def _build_iterator(self, now):</span><br><span class="line">        yield 'processor', 'test'</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class DoubanOutClass(basepoller.BasePollerFT):</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, chassis, config):</span><br><span class="line">        super(DoubanInClass, self).__init__(name, chassis, config)</span><br><span class="line"></span><br><span class="line">    def configure(self):</span><br><span class="line">        super(DoubanInClass, self).configure()</span><br><span class="line">        self.key = self.config.get('key', None)</span><br><span class="line">        self.interval = self.config.get('interval', 80000)</span><br><span class="line"></span><br><span class="line">    def _process_item(self, item):</span><br><span class="line">        return [[item[0], item[1]]]</span><br><span class="line"></span><br><span class="line">    def _build_iterator(self, now):</span><br><span class="line">        yield 'out', 'test'</span><br></pre></td></tr></tbody></table></figure>]]></content>
      
      
      <categories>
          
          <category> MineMeld </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、报警、minemeld </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>minemeld系列～2.minemeld-docker部署</title>
      <link href="/2021/11/11/minemeld-docker-bu-shu-2/"/>
      <url>/2021/11/11/minemeld-docker-bu-shu-2/</url>
      
        <content type="html"><![CDATA[<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>本文采用Docker容器化的方式进行部署。</p><p>MineMeld容器的安装，需要依赖以下内容：</p><ul><li>Docker</li><li>Docker Compose</li><li>Redis容器</li></ul><p><strong>注意</strong>：以下的操作中会使用到两台机器，A服务器 和 B服务器。</p><p>​       A服务器 主要用于生成redis镜像压缩包</p><p>​       B服务器 主要用于安装redis、mimemeld服务</p><h3 id="1-安装Docker-和-Docker-Compose"><a href="#1-安装Docker-和-Docker-Compose" class="headerlink" title="1. 安装Docker 和 Docker Compose"></a>1. 安装Docker 和 Docker Compose</h3><p>​    Docker Compose 使用 yaml 文件使配置变得更加容易，我们可以在其中放置所有配置设置。以下将安装</p><p>安装 Docker：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt update -y &amp;&amp; sudo apt upgrade -y</span><br><span class="line">$ sudo apt install apt-transport-https ca-certificates curl software-properties-common</span><br><span class="line">$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line">$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable"</span><br><span class="line">$ sudo apt update</span><br><span class="line">$ sudo apt install docker-ce</span><br></pre></td></tr></tbody></table></figure><p>安装 Docker-Compose：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo curl -L "https://github.com/docker/compose/releases/download/1.26.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose</span><br><span class="line">$ sudo chmod +x /usr/local/bin/docker-compose</span><br></pre></td></tr></tbody></table></figure><h3 id="2-安装Redis"><a href="#2-安装Redis" class="headerlink" title="2. 安装Redis"></a>2. 安装Redis</h3><p>使用docker-compose进行redis的安装，并导出需要使用到的redis镜像</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkdir /redis</span><br><span class="line">$ cd /redis</span><br><span class="line">$ sudo vim docker-compose.yml</span><br></pre></td></tr></tbody></table></figure><p>确保格式到位，因此没有不必要的空格，否则将无法解析文件。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">version: '3.7'</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line"></span><br><span class="line">  redis:</span><br><span class="line">    container_name: redis</span><br><span class="line">    image: redis</span><br><span class="line">    volumes:</span><br><span class="line">    - "/xxxxx/var/run/redis:/var/run/redis"</span><br><span class="line">    - "/xxxxx/var/lib/redis:/var/lib/redis"</span><br><span class="line">    - "/xxxxx/usr/local/etc/redis:/usr/local/etc/redis"</span><br><span class="line">    command: --appendonly yes</span><br><span class="line">    ports:</span><br><span class="line">    - "6379:6379"</span><br></pre></td></tr></tbody></table></figure><p>注意： 共享本地/xxxxx/usr/local/etc/redis路径，主要是要将该路径下的redis.conf文件映射到镜像的/usr/local/etc/redis/redis.conf。redis.conf为根据启动MimeMeld需求修改的相关启动配置，该文件存放在网盘，网盘链接: <a href="https://pan.baidu.com/s/1ci1jGk03Ery0-ycfhii26A">https://pan.baidu.com/s/1ci1jGk03Ery0-ycfhii26A</a>  提取码的获取请联系我</p><p>要启动容器：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose up -d</span><br></pre></td></tr></tbody></table></figure><p>最后将生成的redis镜像导出成压缩包</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker save redis | gzip &gt; redis.tar.gz</span><br></pre></td></tr></tbody></table></figure><p>A服务器中导出镜像文件后，拷贝redis.tar.gz到B服务器，并执行倒入镜像操作</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker load --input redis.tar.gz</span><br></pre></td></tr></tbody></table></figure><p>B服务器中运行redis容器</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --restart=always --network host -d --name redis -v /usr/local/etc/redis/redis.conf:/usr/local/etc/redis/redis.conf -v /var/lib/redis:/var/lib/redis -v /var/run/redis:/var/run/redis redis redis-server /usr/local/etc/redis/redis.conf</span><br></pre></td></tr></tbody></table></figure><h3 id="3-安装MineMeld"><a href="#3-安装MineMeld" class="headerlink" title="3. 安装MineMeld"></a>3. 安装MineMeld</h3><p>在 B服务器中 创建一个新目录，用于存储 Minemeld 内容和 docker-compose.yml 文件。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sudo mkdir /minemeld</span><br><span class="line">$ cd /minemeld</span><br><span class="line">$ sudo vim docker-compose.yml</span><br></pre></td></tr></tbody></table></figure><p>确保格式到位，因此没有不必要的空格，否则将无法解析文件。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">version: '3.3'</span><br><span class="line">services:</span><br><span class="line">    minemeld:</span><br><span class="line">        container_name: minemeld</span><br><span class="line">        image: paloaltonetworks/minemeld</span><br><span class="line">        restart: always</span><br><span class="line">        tmpfs: /run</span><br><span class="line">        volumes:</span><br><span class="line">            - './minemeld-local:/opt/minemeld/local'</span><br><span class="line">            - './minemeld-logs:/opt/minemeld/logs'</span><br><span class="line">        ports:</span><br><span class="line">            - '443:443'</span><br><span class="line">            - '80:80'</span><br></pre></td></tr></tbody></table></figure><p>要启动容器：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose up -d</span><br></pre></td></tr></tbody></table></figure><p>或者，您可以定义要使用的文件：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker-compose -f docker-compose.yml up -d</span><br></pre></td></tr></tbody></table></figure><h3 id="4-访问MineMeld-Web"><a href="#4-访问MineMeld-Web" class="headerlink" title="4. 访问MineMeld Web"></a>4. 访问MineMeld Web</h3><p>Minemeld 启动并运行安装成功后，默认访问地址为本机IP地址或者127.0.0.1 。默认账号为 admin 、密码为 minemeld。</p><p><img src="/medias/art_img/minemeld-web%E5%9B%BE1.png"></p>]]></content>
      
      
      <categories>
          
          <category> MineMeld </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、报警、minemeld </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>minemeld系列～1.minemeld基础概念</title>
      <link href="/2021/11/10/minemeld-ji-chu-gai-nian-1/"/>
      <url>/2021/11/10/minemeld-ji-chu-gai-nian-1/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="MineMeld介绍"><a href="#MineMeld介绍" class="headerlink" title="MineMeld介绍"></a>MineMeld介绍</h3><p>​    MineMeld是一个开源的威胁情报系统，其实现了收集和共享来自各种来源的威胁情报数据。MineMeld具有高度自动化的收集和聚合威胁指标功能，以及易于使用的Web界面和出色的可视化界面。</p><p>​    MineMeld是开源的，以下讲解MineMeld框架的内容</p><p>​    MineMeld的git wiki地址: <a href="https://github.com/PaloAltoNetworks/minemeld/wiki%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%B8%AE%E5%8A%A9%E6%88%91%E4%BB%AC%E5%BF%AB%E9%80%9F%E7%9A%84%E4%BA%86%E8%A7%A3MineMeld%E6%A1%86%E6%9E%B6%E7%9A%84%E4%BD%BF%E7%94%A8%E7%94%A8%E9%80%94%E3%80%82">https://github.com/PaloAltoNetworks/minemeld/wiki，可以帮助我们快速的了解MineMeld框架的使用用途。</a></p><h3 id="1-MineMeld-代码"><a href="#1-MineMeld-代码" class="headerlink" title="1. MineMeld 代码"></a>1. MineMeld 代码</h3><p>​    MineMeld有两个重要的组件，核心代码组件 和 Web组件</p><p>​    分别的地址为：</p><ul><li><a href="https://github.com/PaloAltoNetworks/minemeld-core">MineMeld-Core</a></li><li><a href="https://github.com/PaloAltoNetworks/minemeld-webui">MineMeld-WebUI</a></li></ul><h3 id="2-MineMeld组件"><a href="#2-MineMeld组件" class="headerlink" title="2. MineMeld组件"></a>2. MineMeld组件</h3><ul><li>miner 是从各种来源收集威胁情报数据的组件，默认情况下预置了一些miner来实现特定用例场景的功能。如Office365</li><li>processor 用于聚合 miner 获取的数据，目的是防止来自miner的重复输入。processor 处理器处于miner 和 output输出源之间</li><li>output输出源基本上是恶意的URL和IP地址的编译列表，该列表可用于安全策略，主要用于阻止来自这些恶意URL和IP地址的流量</li></ul><p>MineMeld的三大组件miner、processor、output的图解如下所示：</p><p><img src="/medias/art_img/minemeld%E7%BB%93%E6%9E%84%E5%9B%BE1.png"></p><p>默认情况下，MineMeld有4个miners、1个processor、3个output</p><h4 id="2-1-miners"><a href="#2-1-miners" class="headerlink" title="2.1 miners"></a>2.1 miners</h4><p>可参考对应的代码模块：minemeld.ft.http.HttpFT</p><ul><li><p>dshield_blocklist ：参考地址 <a href="https://www.dshield.org/">https://www.dshield.org/</a></p></li><li><p>Spamhaus_DROP：参考地址 <a href="https://www.spamhaus.org/">https://www.spamhaus.org/</a>, 保护用户信息安全，在威胁情报领域中起到领导性作用。用于安全过滤器DNSBL（阻止列表）, 以过滤垃圾邮箱为例，参考文档地址为：<a href="https://www.spamhaus.org/whitepapers/dnsbl_function/">https://www.spamhaus.org/whitepapers/dnsbl_function/</a></p></li><li><p>Spamhaus_EDROP：参考地址 <a href="https://www.spamhaus.org/%EF%BC%8C%E5%90%8C%E4%B8%8A">https://www.spamhaus.org/，同上</a></p></li><li><p>wlWhiteListIPv4：白名单列表</p></li></ul><h4 id="2-2-processor"><a href="#2-2-processor" class="headerlink" title="2.2 processor"></a>2.2 processor</h4><p>可参考对应的代码模块：minemeld.ft.ipop.AggregateIPv4FT</p><ul><li>inboundaggregator：聚合处理器</li></ul><h4 id="2-3-output"><a href="#2-3-output" class="headerlink" title="2.3 output"></a>2.3 output</h4><p>将聚合处理器处理的结果输出到redis，可参考对应的代码模块：minemeld.ft.redis.RedisSet</p><ul><li>inboundfeedhc</li><li>inboundfeedlc</li><li>inboundfeedmc</li></ul>]]></content>
      
      
      <categories>
          
          <category> MineMeld </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、报警、minemeld </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>logstash系列～3.logstash grok语法</title>
      <link href="/2021/11/05/logstash-grok-yu-fa-3/"/>
      <url>/2021/11/05/logstash-grok-yu-fa-3/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​    Grok是logstash中最重要的插件，其<strong>能解析任意的文本数据，并转化为具有格式化的数据</strong>，可以配合正则表达式使用。其实主要的思想就是用正则表达式匹配出字段，然后映射成某个字段。</p><p>以下提供两个关于Grok的使用地址，供学习查看：</p><p>1）官网中关于Grok的描述： <a href="https://www.elastic.co/guide/en/kibana/7.9/xpack-grokdebugger.html">https://www.elastic.co/guide/en/kibana/7.9/xpack-grokdebugger.html</a></p><p>2）Grok预定义120个字段，参考：<a href="https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns">https://github.com/logstash-plugins/logstash-patterns-core/tree/master/patterns</a></p><h3 id="1-使用案例"><a href="#1-使用案例" class="headerlink" title="1. 使用案例"></a>1. 使用案例</h3><h4 id="1-1-语法说明"><a href="#1-1-语法说明" class="headerlink" title="1.1 语法说明"></a>1.1 语法说明</h4><p>比如有如下的字符串，需要通过Grok匹配出来：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">localhost GET /index.html 1024 0.016</span><br></pre></td></tr></tbody></table></figure><p>Grok匹配规则解释：</p><p>​    1）localhost 匹配的预定义字段是：IPORHOST</p><p>​    2）GET 匹配的预定义字段是：WORD</p><p>​    3）/index.html 匹配的预定义字段是：URIPATHPARAM</p><p>​    4）1024 匹配的预定义字段是：INT</p><p>​    5）0.016 匹配的预定义字段是：NUMBER</p><p>所以Grok语法就是: %{IPORHOST:client} %{WORD:method} %{URIPATHPARAM:request} %{INT:size} %{NUMBER:duration}</p><h4 id="1-2-logstash-filter说明"><a href="#1-2-logstash-filter说明" class="headerlink" title="1.2 logstash filter说明"></a>1.2 logstash filter说明</h4><p>基于1.1的讲解，可写出如下的filter日志过滤语句：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">filter {</span><br><span class="line">  grok {</span><br><span class="line">    match =&gt; { "message" =&gt; "%{IPORHOST:client} %{WORD:method} %{URIPATHPARAM:request} %{INT:size} %{NUMBER:duration}" }</span><br><span class="line">  }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><h3 id="2-预定义字段说明"><a href="#2-预定义字段说明" class="headerlink" title="2. 预定义字段说明"></a>2. 预定义字段说明</h3><p>​    Grok的预定义字段，其实就是某个字段 用于 表示某个正则表达式。1.1章节只使用到的预定义字段可以从以下的关系中找到对应的正则表达式。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">USERNAME [a-zA-Z0-9._-]+</span><br><span class="line">USER %{USERNAME}</span><br><span class="line">INT (?:[+-]?(?:[0-9]+))</span><br><span class="line">BASE10NUM (?&lt;![0-9.+-])(?&gt;[+-]?(?:(?:[0-9]+(?:\.[0-9]+)?)|(?:\.[0-9]+)))</span><br><span class="line">NUMBER (?:%{BASE10NUM})</span><br><span class="line">BASE16NUM (?&lt;![0-9A-Fa-f])(?:[+-]?(?:0x)?(?:[0-9A-Fa-f]+))</span><br><span class="line">BASE16FLOAT \b(?&lt;![0-9A-Fa-f.])(?:[+-]?(?:0x)?(?:(?:[0-9A-Fa-f]+(?:\.[0-9A-Fa-f]*)?)|(?:\.[0-9A-Fa-f]+)))\b</span><br><span class="line"> </span><br><span class="line">POSINT \b(?:[1-9][0-9]*)\b</span><br><span class="line">NONNEGINT \b(?:[0-9]+)\b</span><br><span class="line">WORD \b\w+\b</span><br><span class="line">NOTSPACE \S+</span><br><span class="line">SPACE \s*</span><br><span class="line">DATA .*?</span><br><span class="line">GREEDYDATA .*</span><br><span class="line">QUOTEDSTRING (?&gt;(?&lt;!\\)(?&gt;"(?&gt;\\.|[^\\"]+)+"|""|(?&gt;'(?&gt;\\.|[^\\']+)+')|''|(?&gt;`(?&gt;\\.|[^\\`]+)+`)|``))</span><br><span class="line">UUID [A-Fa-f0-9]{8}-(?:[A-Fa-f0-9]{4}-){3}[A-Fa-f0-9]{12}</span><br><span class="line"># Networking</span><br><span class="line">MAC (?:%{CISCOMAC}|%{WINDOWSMAC}|%{COMMONMAC})</span><br><span class="line">CISCOMAC (?:(?:[A-Fa-f0-9]{4}\.){2}[A-Fa-f0-9]{4})</span><br><span class="line">WINDOWSMAC (?:(?:[A-Fa-f0-9]{2}-){5}[A-Fa-f0-9]{2})</span><br><span class="line">COMMONMAC (?:(?:[A-Fa-f0-9]{2}:){5}[A-Fa-f0-9]{2})</span><br><span class="line">IPV6 ((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:)))(%.+)?</span><br><span class="line">IPV4 (?&lt;![0-9])(?:(?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2}))(?![0-9])</span><br><span class="line">IP (?:%{IPV6}|%{IPV4})</span><br><span class="line">HOSTNAME \b(?:[0-9A-Za-z][0-9A-Za-z-]{0,62})(?:\.(?:[0-9A-Za-z][0-9A-Za-z-]{0,62}))*(\.?|\b)</span><br><span class="line">HOST %{HOSTNAME}</span><br><span class="line">IPORHOST (?:%{HOSTNAME}|%{IP})</span><br><span class="line">HOSTPORT %{IPORHOST}:%{POSINT}</span><br><span class="line"># paths</span><br><span class="line">PATH (?:%{UNIXPATH}|%{WINPATH})</span><br><span class="line">UNIXPATH (?&gt;/(?&gt;[\w_%!$@:.,-]+|\\.)*)+</span><br><span class="line">TTY (?:/dev/(pts|tty([pq])?)(\w+)?/?(?:[0-9]+))</span><br><span class="line">WINPATH (?&gt;[A-Za-z]+:|\\)(?:\\[^\\?*]*)+</span><br><span class="line">URIPROTO [A-Za-z]+(\+[A-Za-z+]+)?</span><br><span class="line">URIHOST %{IPORHOST}(?::%{POSINT:port})?</span><br><span class="line"># uripath comes loosely from RFC1738, but mostly from what Firefox</span><br><span class="line"># doesn't turn into %XX</span><br><span class="line">URIPATH (?:/[A-Za-z0-9$.+!*'(){},~:;=@#%_\-]*)+</span><br><span class="line">#URIPARAM \?(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?(?:&amp;(?:[A-Za-z0-9]+(?:=(?:[^&amp;]*))?)?)*)?</span><br><span class="line">URIPARAM \?[A-Za-z0-9$.+!*'|(){},~@#%&amp;/=:;_?\-\[\]]*</span><br><span class="line">URIPATHPARAM %{URIPATH}(?:%{URIPARAM})?</span><br><span class="line">URI %{URIPROTO}://(?:%{USER}(?::[^@]*)?@)?(?:%{URIHOST})?(?:%{URIPATHPARAM})?</span><br><span class="line"># Months: January, Feb, 3, 03, 12, December</span><br><span class="line">MONTH \b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\b</span><br><span class="line">MONTHNUM (?:0?[1-9]|1[0-2])</span><br><span class="line">MONTHNUM2 (?:0[1-9]|1[0-2])</span><br><span class="line">MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])</span><br><span class="line"># Days: Monday, Tue, Thu, etc...</span><br><span class="line">DAY (?:Mon(?:day)?|Tue(?:sday)?|Wed(?:nesday)?|Thu(?:rsday)?|Fri(?:day)?|Sat(?:urday)?|Sun(?:day)?)</span><br><span class="line"># Years?</span><br><span class="line">YEAR (?&gt;\d\d){1,2}</span><br><span class="line">HOUR (?:2[0123]|[01]?[0-9])</span><br><span class="line">MINUTE (?:[0-5][0-9])</span><br><span class="line"># '60' is a leap second in most time standards and thus is valid.</span><br><span class="line">SECOND (?:(?:[0-5]?[0-9]|60)(?:[:.,][0-9]+)?)</span><br><span class="line">TIME (?!&lt;[0-9])%{HOUR}:%{MINUTE}(?::%{SECOND})(?![0-9])</span><br><span class="line"># datestamp is YYYY/MM/DD-HH:MM:SS.UUUU (or something like it)</span><br><span class="line">DATE_US %{MONTHNUM}[/-]%{MONTHDAY}[/-]%{YEAR}</span><br><span class="line">DATE_EU %{MONTHDAY}[./-]%{MONTHNUM}[./-]%{YEAR}</span><br><span class="line">ISO8601_TIMEZONE (?:Z|[+-]%{HOUR}(?::?%{MINUTE}))</span><br><span class="line">ISO8601_SECOND (?:%{SECOND}|60)</span><br><span class="line">TIMESTAMP_ISO8601 %{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND})?%{ISO8601_TIMEZONE}?</span><br><span class="line">DATE %{DATE_US}|%{DATE_EU}</span><br><span class="line">DATESTAMP %{DATE}[- ]%{TIME}</span><br><span class="line">TZ (?:[PMCE][SD]T|UTC)</span><br><span class="line">DATESTAMP_RFC822 %{DAY} %{MONTH} %{MONTHDAY} %{YEAR} %{TIME} %{TZ}</span><br><span class="line">DATESTAMP_RFC2822 %{DAY}, %{MONTHDAY} %{MONTH} %{YEAR} %{TIME} %{ISO8601_TIMEZONE}</span><br><span class="line">DATESTAMP_OTHER %{DAY} %{MONTH} %{MONTHDAY} %{TIME} %{TZ} %{YEAR}</span><br><span class="line">DATESTAMP_EVENTLOG %{YEAR}%{MONTHNUM2}%{MONTHDAY}%{HOUR}%{MINUTE}%{SECOND}</span><br><span class="line"># Syslog Dates: Month Day HH:MM:SS</span><br><span class="line">SYSLOGTIMESTAMP %{MONTH} +%{MONTHDAY} %{TIME}</span><br><span class="line">PROG (?:[\w._/%-]+)</span><br><span class="line">SYSLOGPROG %{PROG:program}(?:\[%{POSINT:pid}\])?</span><br><span class="line">SYSLOGHOST %{IPORHOST}</span><br><span class="line">SYSLOGFACILITY &lt;%{NONNEGINT:facility}.%{NONNEGINT:priority}&gt;</span><br><span class="line">HTTPDATE %{MONTHDAY}/%{MONTH}/%{YEAR}:%{TIME} %{INT}</span><br><span class="line"># Shortcuts</span><br><span class="line">QS %{QUOTEDSTRING}</span><br><span class="line"># Log formats</span><br><span class="line">SYSLOGBASE %{SYSLOGTIMESTAMP:timestamp} (?:%{SYSLOGFACILITY} )?%{SYSLOGHOST:logsource} %{SYSLOGPROG}:</span><br><span class="line">COMMONAPACHELOG %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] "(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})" %{NUMBER:response} (?:%{NUMBER:bytes}|-)</span><br><span class="line">COMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent}</span><br><span class="line"># Log Levels</span><br><span class="line">LOGLEVEL ([Aa]lert|ALERT|[Tt]race|TRACE|[Dd]ebug|DEBUG|[Nn]otice|NOTICE|[Ii]nfo|INFO|[Ww]arn?(?:ing)?|WARN?(?:ING)?|[Ee]rr?(?:or)?|ERR?(?:OR)?|[Cc]rit?(?:ical)?|CRIT?(?:ICAL)?|[Ff]atal|FATAL|[Ss]evere|SEVERE|EMERG(?:ENCY)?|[Ee]merg(?:ency)?)</span><br></pre></td></tr></tbody></table></figure><h3 id="3-Grok调试工具"><a href="#3-Grok调试工具" class="headerlink" title="3. Grok调试工具"></a>3. Grok调试工具</h3><p>​    Kibana中自带的Grok Debugger可以很方便的将输入的日志 映射成 匹配的格式，映射之后是一个key:value的形式。</p>]]></content>
      
      
      <categories>
          
          <category> Logstash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、logstash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>logstash系列～2.logstash部署</title>
      <link href="/2021/11/04/logstash-bu-shu-2/"/>
      <url>/2021/11/04/logstash-bu-shu-2/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        从上一章的内容中可以了解到logstash的工作原理 以及 logstash在大数据分析平台中所处的位置。logstash作为数据采集、数据分析等任务的处理核心组件，首先我们需要将其运行起来，并调试日志信息的接收和打印。</p><p><strong>注意</strong>：默认当前环境已经安装好docker环境了～</p><h3 id="1-logstash镜像拉取"><a href="#1-logstash镜像拉取" class="headerlink" title="1. logstash镜像拉取"></a>1. logstash镜像拉取</h3><p>拉取指定7.8.1版本的logstash镜像</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull logstash:7.8.1</span><br></pre></td></tr></tbody></table></figure><h3 id="2-输入与输出的简单配置"><a href="#2-输入与输出的简单配置" class="headerlink" title="2. 输入与输出的简单配置"></a>2. 输入与输出的简单配置</h3><h4 id="2-1-代码路径"><a href="#2-1-代码路径" class="headerlink" title="2.1 代码路径"></a>2.1 代码路径</h4><p>├── logstatsh_study<br>​    ├── config<br>​        &nbsp;&nbsp; └── logstash.yml<br>​    ├── pipeline<br>​        &nbsp;&nbsp; └── in.conf<br>​        &nbsp;&nbsp; └── out.conf<br>​    ├── syslog.py<br>​    ├── udp.py</p><p>代码路径解释：</p><p>config文件夹下存放的是配置文件logstash.yml，配置与logstash相关的配置。</p><p>pipeline文件夹为管道文件，主要存放的是接收、输出、过滤日志信息的conf配置文件</p><p>syslog.py和dup.py文件，主要用于测试，实现推送日志信息</p><h4 id="2-2-logstash-yml配置"><a href="#2-2-logstash-yml配置" class="headerlink" title="2.2 logstash.yml配置"></a>2.2 logstash.yml配置</h4><p>​        在logstash.yml文件中设置如何运行logstash，当然也可以在启动logstash的时候在命令行中指定，所有在命令行中指定的参数会覆盖此文件中的配置。</p><p>如下是我在logstash.yml中定义的内容：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">http.host: "0.0.0.0"</span><br><span class="line">path.logs: /var/log/logstash</span><br><span class="line">config.reload.automatic: true</span><br></pre></td></tr></tbody></table></figure><p>参数解释：</p><p>​    config.reload.automatic: true  表示：自动检测配置文件变动并自动重载。</p><p>​    path.logs 表示：设置日志存储的位置</p><p>​    http.host 表示：设置绑定的Ip地址</p><p>​    http.port 表示：设置绑定的端口</p><p>以下罗列了logstash.yml中其他的参数: </p><table><thead><tr><th>Setting</th><th>Description（描述）</th><th>Default value（默认值）</th></tr></thead><tbody><tr><td><code>node.name</code></td><td>节点的描述性名称。</td><td>Machine’s hostname</td></tr><tr><td><code>path.data</code></td><td>Logstash及其插件持久化的数据的目录</td><td><code>LOGSTASH_HOME/data</code></td></tr><tr><td><code>pipeline.id</code></td><td>The ID of the pipeline.</td><td><code>main</code></td></tr><tr><td><code>pipeline.workers</code></td><td>管道中filter和output阶段并行工作的worker的数量。 如果发现事件正在备份，或者CPU未饱和，请考虑增加此数量以更好地利用机器处理能力。</td><td>CPU核心数量</td></tr><tr><td><code>pipeline.batch.size</code></td><td>前面有提到，用来定义worker每次从inputs发送到中央队列中取出的batch的数量。更大的数量通常意味着更好的性能，但也会占用更多的内存，你可以在 <code>jvm.options</code>文件中增加JVM堆空间。更多信息参考： <a href="https://www.kancloud.cn/aiyinsi-tan/logstash/849598">Logstash配置文件</a></td><td><code>125</code></td></tr><tr><td><code>pipeline.batch.delay</code></td><td>当创建管道数据batch都时候，worker等待inputs数据的时间，即使没有拿到<code>batch.size</code>定义的数据量。</td><td><code>50</code></td></tr><tr><td><code>pipeline.unsafe_shutdown</code></td><td>当此项设置为<code>true</code>的时候，在收到shutdown事件的时候Logstash会强制退出，即使仍有数据在内存中。默认情况下，Logstash会拒绝退出直到所有接收到的数据发送给outputs。启用此选项可能导致在关闭期间丢失数据。</td><td><code>false</code></td></tr><tr><td><code>path.config</code></td><td>指定主管道配置文件路径，如果路径是目录或者通配符，Logstash会根据字母顺序进行读取。</td><td></td></tr><tr><td><code>config.string</code></td><td>包含用于主管道配置的一个字符串。和配置文件语法相同。</td><td>None</td></tr><tr><td><code>config.test_and_exit</code></td><td>当此项设置为<code>true</code>的时候，会检查配置文件，在完成之后退出。注意此项设置不会检查Grok匹配的正确性。 Logstash 可以从目录中读取多个配置文件。如果此项配置结合 <code>log.level: debug</code>,Logstash会对组合的配置的每一个配置添加注释。（Logstash会将配置文件中的每一项以Debug的形式显示出来）</td><td><code>false</code></td></tr><tr><td><code>config.reload.automatic</code></td><td>当此项设置为<code>true</code>的时候，程序会周期性的检查配置文件的变化，并在有变化的时候重新加载配置文件。可以通过给进程发送SIGHUP信号来重读配置文件。</td><td><code>false</code></td></tr><tr><td><code>config.reload.interval</code></td><td>Logstash检查配置文件变动的频率。</td><td><code>3s</code></td></tr><tr><td><code>config.debug</code></td><td>设置为 <code>true</code>的时候,将完整的编译配置作为debug日志消息。同时必须设置 <code>log.level: debug</code>. WARNING: 日志信息会包含明文密码。可能会导致你的密码明文出现在你的日志中。原文：The log message will include any <em>password</em> options passed to plugin configs as plaintext, and may result in plaintext passwords appearing in your logs!</td><td><code>false</code></td></tr><tr><td><code>config.support_escapes</code></td><td>设置为<code>true</code>之后，将处理一下转意: <code>\n</code> 转成换行符 (ASCII 10). <code>\r</code> 转成回车(ASCII 13). <code>\t</code> 转成tab (ASCII 9). <code>\\</code> 转成”"本身 <code>\</code>. <code>\"</code> 变成双引号 <code>\'</code>变成引号</td><td><code>false</code></td></tr><tr><td><code>modules</code></td><td>When configured, <code>modules</code> must be in the nested YAML structure described above this table.</td><td>None</td></tr><tr><td><code>queue.type</code></td><td>用于事件缓冲的内部队列模型。 设置为 <code>memory</code> 使用基于内存的队列, 或设置为 <code>persisted</code> 使用基于磁盘的 ACKed 队列 (<a href="https://www.elastic.co/guide/en/logstash/current/persistent-queues.html">persistent queues</a>).</td><td><code>memory</code></td></tr><tr><td><code>path.queue</code></td><td>启用持久化队列时的数据存储目录。 (<code>queue.type: persisted</code>).</td><td><code>path.data/queue</code></td></tr><tr><td><code>queue.page_capacity</code></td><td>启用持久化队列时可以使用的页面文件大小。 (<code>queue.type: persisted</code>). The queue data consists of append-only data files separated into pages.</td><td>64mb</td></tr><tr><td><code>queue.max_events</code></td><td>启用持久化之后队列中未读事件的最大数量。 (<code>queue.type: persisted</code>).</td><td>0 (unlimited)</td></tr><tr><td><code>queue.max_bytes</code></td><td>队列最大的容量，以字节为单位，确保你定义的位置的磁盘上有足够的空间。 如果<code>queue.max_events</code>和<code>queue.max_bytes</code>同时定义，先到达的会生效。也就是小的生效。</td><td>1024mb (1g)</td></tr><tr><td><code>queue.checkpoint.acks</code></td><td>持久化队列开启的情况下，强制检查点之前ACKed事件的最大数量。 (<code>queue.type: persisted</code>)。 设置为0表示不限制：<code>queue.checkpoint.acks: 0</code></td><td>1024</td></tr><tr><td><code>queue.checkpoint.writes</code></td><td>持久化队列开启的情况下，强制检查点之前writes事件的最大数量。 (<code>queue.type: persisted</code>)。 设置为0表示不限制：<code>queue.checkpoint.writes: 0</code></td><td>1024</td></tr><tr><td><code>queue.drain</code></td><td>开启之后，Logstash处理完成持久化队列之后才会关闭。</td><td>false</td></tr><tr><td><code>dead_letter_queue.enable</code></td><td>开启由插件提供的DLQ功能。</td><td><code>false</code></td></tr><tr><td><code>dead_letter_queue.max_bytes</code></td><td>每个dead letter队列的最大值。 超出的部分会被删除。</td><td><code>1024mb</code></td></tr><tr><td><code>path.dead_letter_queue</code></td><td>存储dead-letter队列的目录。</td><td><code>path.data/dead_letter_queue</code></td></tr><tr><td><code>http.host</code></td><td>设置绑定的IP地址</td><td><code>"127.0.0.1"</code></td></tr><tr><td><code>http.port</code></td><td>设置绑定的端口</td><td><code>9600</code></td></tr><tr><td><code>log.level</code></td><td>设置日志级别，有以下几种: <code>fatal``error``warn``info``debug``trace</code></td><td><code>info</code></td></tr><tr><td><code>log.format</code></td><td>设置日志格式。设置为<code>json</code>以JSON格式记录日志。或这只为 <code>plain</code> 使用 <code>Object#.inspect</code>记录日志。（应该是设置Logstash日志格式）</td><td><code>plain</code></td></tr><tr><td><code>path.logs</code></td><td>The directory where Logstash will write its log to.</td><td><code>LOGSTASH_HOME/logs</code></td></tr><tr><td><code>path.plugins</code></td><td>指定Logstash搜索插件的目录，可以多次设置以设置多个查检目录。目录必须遵循以下结构: <code>PATH/logstash/TYPE/NAME.rb</code>其中<code>TYPE</code> is <code>inputs</code>, <code>filters</code>, <code>outputs</code>, 或 <code>codecs</code>, <code>NAME</code>就是插件的名字。</td><td></td></tr></tbody></table><h4 id="2-3-pipeline管道配置"><a href="#2-3-pipeline管道配置" class="headerlink" title="2.3 pipeline管道配置"></a>2.3 pipeline管道配置</h4><p>​    从Logstash6.0开始，引入了Multiple Pipeline，用户可以在./config/pipeline.yml中配置单管道 或 多管道，并指定管道配置文件在./pipeline/in.conf文件和./pipeline/out.conf文件。启动logstash后，如果安装了X-Pack插件，就可以在<strong>Kibana-&gt;Monitoring-&gt;Logstash</strong> 中看到相关的管道信息。</p><p>以下在pipeline文件夹下定义接收和输出日志的管道文件：</p><h5 id="2-2-1-in-conf为定义接收日志的规则文件"><a href="#2-2-1-in-conf为定义接收日志的规则文件" class="headerlink" title="2.2.1 in.conf为定义接收日志的规则文件"></a>2.2.1 in.conf为定义接收日志的规则文件</h5><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">input {</span><br><span class="line">    syslog { </span><br><span class="line">        port =&gt; 514</span><br><span class="line">        grok_pattern =&gt; "&lt;%{POSINT:priority}&gt;%{GREEDYDATA:message}"</span><br><span class="line">        tags =&gt; "linux"</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><strong>说明</strong>：通过514端口接收系统日志。其中使用grok组件来解析传入的数据，并转化具有结构化的数据。grok的详细用法方法，请看logstash-grok组件的使用规则</p><h5 id="2-2-2-out-conf为定义输出日志的规则文件"><a href="#2-2-2-out-conf为定义输出日志的规则文件" class="headerlink" title="2.2.2 out.conf为定义输出日志的规则文件"></a>2.2.2 out.conf为定义输出日志的规则文件</h5><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output {</span><br><span class="line">  stdout { codec =&gt; rubydebug }</span><br><span class="line">}</span><br></pre></td></tr></tbody></table></figure><p><strong>说明</strong>：rubydebug其实就是codec的一种编码格式，方便我们测试和调试，美化output输出，也可以理解成对输出进行格式化。</p><h3 id="3-logstash-启动"><a href="#3-logstash-启动" class="headerlink" title="3. logstash 启动"></a>3. logstash 启动</h3><p>在in.conf管道文件中配置了接收<strong>端口为514的系统日志syslog</strong>，因此需要配置防火墙ACLs，参考地址：<a href="https://discuss.elastic.co/t/logstash-bind-to-port-514/44022/9">https://discuss.elastic.co/t/logstash-bind-to-port-514/44022/9</a></p><h4 id="3-1-防火墙"><a href="#3-1-防火墙" class="headerlink" title="3.1 防火墙"></a>3.1 防火墙</h4><p>syslog 端口日志转发命令，如下：</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo firewall-cmd --permanent --zone=internal --add-port=514/udp #syslog port</span><br></pre></td></tr></tbody></table></figure><h4 id="3-2-Docker容器启动"><a href="#3-2-Docker容器启动" class="headerlink" title="3.2 Docker容器启动"></a>3.2 Docker容器启动</h4><p>docker容器启动的时候，需要注意以下几点：</p><p>1）需要映射logstash.yml文件路径，即本地的logstash.yml必须与容器的/usr/share/logstash/config/logstash.yml形成映射关系。</p><p>2）需要映射管道pipeline文件夹，即本地pipeline文件夹必须与容器的/usr/share/logstash/pipeline文件夹形成映射关系。</p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd -u root -p 514:514/udp -v /media/psf/Home/study_workspace/logstatsh_study/config/logstash.yml:/usr/share/logstash/config/logstash.yml -v /media/psf/Home/study_workspace/logstatsh_study/pipeline/:/usr/share/logstash/pipeline/ --name=logstash  logstash:7.8.1</span><br></pre></td></tr></tbody></table></figure><h3 id="4-调试"><a href="#4-调试" class="headerlink" title="4. 调试"></a>4. 调试</h3><p>模拟向系统日志syslog 514端口发送日志消息，并在name为logstash的容器中查看接收并输出的日志信息。</p><p>syslog.py中的代码逻辑如下：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> logging.handlers</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">'syslogtest'</span>)</span><br><span class="line">logger.setLevel(logging.INFO)</span><br><span class="line">sh = logging.handlers.SysLogHandler((<span class="string">'127.0.0.1'</span>, <span class="number">514</span>), logging.handlers.SysLogHandler.LOG_AUTH)</span><br><span class="line">logger.addHandler(sh)</span><br><span class="line"></span><br><span class="line">siplist = [<span class="string">'212.92.30.69'</span>, <span class="string">'94.74.172.218'</span>, <span class="string">'120.133.136.75'</span>, <span class="string">'49.36.247.72'</span>, <span class="string">'222.180.208.14'</span>, <span class="string">'111.19.157.70'</span>,</span><br><span class="line">           <span class="string">'133.18.208.232'</span>, <span class="string">'118.89.230.32'</span>, <span class="string">'184.145.167.92'</span>, <span class="string">'128.199.229.253'</span>, <span class="string">'61.224.201.44'</span>, <span class="string">'138.122.111.213'</span>,</span><br><span class="line">           <span class="string">'37.238.120.4'</span>]</span><br><span class="line">shashlist = [<span class="string">'00004e073dde06b8e0b462ac3c8bcc15'</span>]</span><br><span class="line"></span><br><span class="line">data = <span class="string">'May 25 11:11:56 localhost fwlog: 日志类型:WEB应用防护, 策略名称:waf1, 规则ID:0, 源IP:'</span> + siplist[<span class="number">0</span>] + \</span><br><span class="line">       <span class="string">', 源端口:7224, 目的IP:192.168.254.31, 目的端口:80, 攻击类型:跨站请求伪造, 严重级别:低, 系统动作:允许, '</span> \</span><br><span class="line">       <span class="string">'URL:flag-760768087.amarilisperu.com/gate.html?location=09952f492400cff5b1680b990e21fe18 '</span></span><br><span class="line">logger.info(data)</span><br></pre></td></tr></tbody></table></figure><p>通过portainer进行查看name为logstash的容器日志，可以发现执行python syslog.py命令后，容器的日志中正常打印了接收日志的内容，并通过grok进行了结构化的处理，如下图所示：</p><p><img src="/medias/art_img/logstash%E6%97%A5%E5%BF%97%E6%89%93%E5%8D%B01.png"></p>]]></content>
      
      
      <categories>
          
          <category> Logstash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、logstash </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>logstash系列～1.基础概念</title>
      <link href="/2021/11/02/logstash-ji-chu-gai-nian-1/"/>
      <url>/2021/11/02/logstash-ji-chu-gai-nian-1/</url>
      
        <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​    Logstash 是 Elastic Stack 的中央数据流引擎，用于收集、丰富和统一所有数据，而不管格式或模式。当与Elasticsearch，Kibana，及 Beats 共同使用的时候便会拥有特别强大的实时处理能力。</p><p>本章中核心重点包括：</p><ul><li>Logstash 概念与术语</li><li>内部架构和重要设置</li></ul><h3 id="1-Logstash的工作原理"><a href="#1-Logstash的工作原理" class="headerlink" title="1. Logstash的工作原理"></a>1. Logstash的工作原理</h3><p>​        logstash的事件处理流程分为三个阶段：inputs - - - &gt; filers - - - &gt; outputs，即 接受输入的日志 —&gt; 按过滤条件进行处理日志 —&gt; 输出过滤后的日志。其支持所有抛出的日志类型数据。</p><p>简单的结构图：</p><p><img src="/medias/art_img/logstash%E7%BB%93%E6%9E%84%E5%9B%BE1.png"></p><h4 id="1-1-inputs-输入"><a href="#1-1-inputs-输入" class="headerlink" title="1.1 inputs 输入"></a>1.1 inputs 输入</h4><p>​    常见的输入有以下几点：</p><p>​    1）syslog：监听514端口上的系统日志信息</p><p>​    2）udp：监听指定的udp端口</p><p>​    3）file: 从文件系统的文件中读取日志信息，类似tail -f命令</p><p>​    4）redis：从redis service中读取</p><p>​    5）beats：从filebeat中读取</p><h4 id="1-2-filters-日志过滤"><a href="#1-2-filters-日志过滤" class="headerlink" title="1.2 filters 日志过滤"></a>1.2 filters 日志过滤</h4><p>​    常用的过滤器有以下几个：</p><p>​    1）grok：logstash中最重要的插件，其<strong>能解析任意的文本数据，并转化为具有格式化的数据</strong>。可以配合正则表达式使用</p><p>​    2）mutate：对字段进行处理。如对字段进行删除、修改、重命名、替换等操作</p><p>​    3）geoip：添加地理位置信息，用户kibana图形化显示使用</p><p>​    4）drop：丢弃部分数据</p><p>​    5）clone：拷贝数据，这个过程可以添加或删除字段</p><h4 id="1-3-outputs-输出"><a href="#1-3-outputs-输出" class="headerlink" title="1.3 outputs 输出"></a>1.3 outputs 输出</h4><p>​    常用的输出 有以下几个：</p><p>​    1）elasticsearch：用es服务进行数据的存储</p><p>​    2）file：将输出数据保存到文本中</p><p>​    3）graphite：将数据发送到图形化组件中</p><p>​    4）json：使用json格式数据进行编码    / 解码</p><p>​    5）multiline：将多个事件的数据汇总为一个单行数据</p><h3 id="2-logstash在数据分析中的位置"><a href="#2-logstash在数据分析中的位置" class="headerlink" title="2. logstash在数据分析中的位置"></a>2. logstash在数据分析中的位置</h3><p>​    logstash在整个结构中起到数据采集，格式化，数据过滤等处理，最终数据推到ES做存储。其logstash在整个架构中的图解如下：</p><p><img src="/medias/art_img/logstash%E7%BB%93%E6%9E%84%E5%9B%BE2.png"></p>]]></content>
      
      
      <categories>
          
          <category> Logstash </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据、logstash </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
